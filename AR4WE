#!/bin/bash

# Author: Zakaria Farahi & Saad Lili & Haraoui Souhaib
# Created: 10 May 2024
# Last modified: 10 May 2024

# Description: This script is used to do reconaissance on a target domain. It uses various tools to gather information about the target domain.

# Usage: AR4WE [options] <domain>
# Options:
# -h, --help: Display help message
# -V, --verbose: Display verbose output

# 100 : exit code for help message
# 1 : exit code for not root user
# 101 : exit code for invalid option
# 102 : exit code for domain not provided or invalid

clear

echo "
      .o.       ooooooooo.         .o   oooooo   oooooo     oooo oooooooooooo 
     .888.      \`888   \`Y88.     .d88    \`888.    \`888.     .8'  \`888'     \`8 
    .8\"888.      888   .d88'   .d'888     \`888.   .8888.   .8'    888         
   .8' \`888.     888ooo88P'  .d'  888      \`888  .8'\`888. .8'     888oooo8    
  .88ooo8888.    888\`88b.    88ooo888oo     \`888.8'  \`888.8'      888    \"    
 .8'     \`888.   888  \`88b.       888        \`888'    \`888'       888       o 
o88o     o8888o o888o  o888o     o888o        \`8'      \`8'       o888ooooood8 
                                                                          
"

# Check if running as root
if [ "$EUID" -ne 0 ]; then
    echo "Please run as root"
    exit 1
fi

optionHelp() {
    echo "Usage: AR4WE [options] <domain>"
    echo "Options:"
    echo "-h, --help: Display help message"
    echo "-V, --verbose: Display verbose output"
}

# Check if the first argument is help or empty
if [ "$1" == "-h" ] || [ "$1" == "--help" ] || [ -z "$1" ]; then
    optionHelp
    exit 100
fi

# Variables to store options
verbose=false

# Parse options
while getopts ":Vh" option; do
    case $option in
    V) verbose=true ;;
    h)
        optionHelp
        exit 0
        ;;
    \?)
        echo "Invalid option: -$OPTARG" >&2
        exit 101
        ;;
    esac
done

# Shift the parsed options
shift $((OPTIND - 1))

# Get the domain
domain="$1"

# Check if domain is provided
if [ -z "$domain" ] || ! [[ $domain =~ ^.+\..+$ ]]; then
    echo "Error: Domain not provided or invalid. Please provide a valid domain."
    exit 102
fi

# Use the domain variable as needed
echo "Domain: $domain"
echo "Verbose: $verbose"

# start
echo "Starting reconaissance on $domain"

# Create a directories to store the results

if [ ! -d "$domain" ]; then
    mkdir -p $domain
else
    echo "Directory already exists"
    # compress backup the directory if it already exists then delete its content
    date=$(date '+%Y-%m-%d_%H-%M-%S')
    tar -czvf $domain-$date.tar.gz $domain
    rm -rf $domain/*
fi

cd $domain

mkdir -p Domain_Info lastPart/backurl/gau lastPart/backurl/wayback lastPart/contentDir/DirSearch lastPart/contentDir/fuzz lastPart/JsFiles lastPart/subSub/AltDNS liveSubDom/httpx port_Scan/masscan port_Scan/nmap Subdomain/Amass Subdomain/Sublist3r Subdomain/Subfinder logs wordlists screenshots/ wordlists/dirb
touch Domain_Info/DNS_Rec.txt Domain_Info/whois.txt lastPart/backurl/gau/res_gau.txt lastPart/backurl/res_final.txt lastPart/backurl/res_way.txt lastPart/contentDir/DirSearch/res_Dir.txt lastPart/contentDir/fuzz/res_f.txt lastPart/contentDir/res_final.txt lastPart/JsFiles/js_url.txt lastPart/subSub/AltDNS/res.txt liveSubDom/httpx/live.txt port_Scan/masscan/res_mass.txt port_Scan/nmap/res_nmap.txt Subdomain/Amass/res_amass.txt Subdomain/ip_add.txt Subdomain/subdomains_filterd.txt Subdomain/Sublist3r/res_Sub.txt Subdomain/Subfinder/res_subfinder.txt port_Scan/masscan/ips port_Scan/masscan/temp port_Scan/masscan/open_ports wordlists/dirb/common.txt

# Define the project and spider names
project_name="urlsJsScraper"
# Function to set up Scrapy project and spiders
setup_scrapy_project() {
    # Create Scrapy project
    scrapy startproject urlsJsScraper
    if [ $? -eq 0 ]; then # Check if scrapy command succeeded
        echo "Scrapy project urlsJsScraper created successfully."
        mkdir -p lastPart
        mv urlsJsScraper lastPart/
        cd "./lastPart/urlsJsScraper"

        # Write the spider code to a new file in the spiders directory
        cat <<EOF >"urlsJsScraper/spiders/url_extractor.py"
import scrapy

class UrlExtractorSpider(scrapy.Spider):
    name = 'url_extractor'

    def __init__(self, subdomains_file=None, *args, **kwargs):
        super(UrlExtractorSpider, self).__init__(*args, **kwargs)
        self.subdomains_file = subdomains_file

    def start_requests(self):
        if self.subdomains_file:
            with open(self.subdomains_file, "r") as file:
                urls = [url.strip() for url in file.readlines() if url.strip()]
            for url in urls:
                if not url.startswith(('http://', 'https://')):
                    url = 'http://' + url
                yield scrapy.Request(url=url, callback=self.parse)
        else:
            self.logger.error("Subdomains file not provided.")
            return  # Stop the spider if no file is provided

    def parse(self, response):
        # Extract all links and JS file paths
        for link in response.css('a::attr(href)').getall():
            yield {'url': response.urljoin(link)}
        for script in response.css('script::attr(src)').getall():
            if script:  # Check if the src attribute is not empty
                yield {'js_path': response.urljoin(script)}
EOF
        echo "Spider code has been written to urlsJsScraper/spiders/url_extractor.py"
        cd ../../
    else
        echo "Failed to create project directory urlsJsScraper"
        return 1
    fi
}
# call setup scrapy prject
setup_scrapy_project

# download this wordlist : https://raw.githubusercontent.com/cujanovic/dirsearch-wordlist/master/serbian-english-wordlist-final-dirsearch-format-with-ext.txt
# Domain Information
#####################################
domainInfo() {
# For INFO log
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : starting domain information gathering with whois" >> log/logs_file.txt
    whois "$domain" >Domain_Info/whois.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with whois" >> logs/logs_file.txt
        $domainCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of whois" >> logs/logs_file.txt

    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the start of nslookup  " >> log/logs_file.txt
    nslookup "$domain" >Domain_Info/DNS_Rec.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with nslookup" >> logs/logs_file.txt
        $domainCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of nslookup" >> log/logs_file.txt
}

# Call
callDomainInfo() {
    domainCheck=true
    domainInfo
    if [ $domainCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : lDomain Information failed" >> logs/logs_file.txt
        domainInfo
        if [ $domainCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : lDomain Information failed" >> logs/logs_file.txt
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}

#callDomainInfo
#####################################
# Subdomain Enumeration
subEnum() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the start of sublist3r" >> log/logs_file.txt
    sublist3r -d $domain -o Subdomain/Sublist3r/res_Sub.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems sublist3r" >> logs/logs_file.txt
        $subCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of sublist3r" >> log/logs_file.txt
    

    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the start of amass" >> log/logs_file.txt
    amass enum -d $domain -o Subdomain/Amass/res_amass.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with amass" >> logs/logs_file.txt
        $subCheck=false
    else
        grep -Eo "([0-9]{1,3}\.){3}[0-9]{1,3}" Subdomain/Amass/res_amass.txt >Subdomain/ip_add.txt
        grep -Eo "([a-z0-9A-Z]+\.[a-z0-9A-Z]+\.?[a-z0-9A-Z]+)" Subdomain/Amass/res_amass.txt >Subdomain/Amass/res_amass.txt

    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of amass" >> log/logs_file.txt


    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the start of subfinder" >> log/logs_file.txt
    subfinder -d $domain -o Subdomain/Subfinder/res_subfinder.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with subfinder" >> logs/logs_file.txt
        $subCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of subfinder" >> log/logs_file.txt

    # merge the resulates of sublist3r and amass
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of merge the resulates of sublist3r and amass " >> log/logs_file.txt
    cat Subdomain/Sublist3r/res_Sub.txt Subdomain/Amass/res_amass.txt Subdomain/Subfinder/res_subfinder.txt >Subdomain/subdomains_filterd.txt
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : end of merge the resulates of sublist3r and amass " >> log/logs_file.txt

    # get the ip addresses of the subdomains
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of getting ip addresses" >> log/logs_file.txt
    while read subdomain; do
        dig +short "$subdomain" | awk '/([0-9]{1,3}\.){3}[0-9]{1,3}/ { print $1 }' >>Subdomain/ip_add.txt
    done <Subdomain/subdomains_filterd.txt
    # remove duplicates ip
    sort -u Subdomain/ip_add.txt -o Subdomain/ip_add.txt
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : end of getting ip addresses" >> log/logs_file.txt
}
# Call
callSubEnum() {
    subCheck=true
    subEnum
    if [ $subCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR :  Subdomain Enumeration failed" >> logs/logs_file.txt
        subEnum
        if [ $subCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : Error: Subdomain Enumeration failed" >> logs/logs_file.txt
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt
        fi
    fi
}
callSubEnum
#####################################
# live subdomains
liveSub() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of httpx" >> log/logs_file.txt
    httpx -l Subdomain/subdomains_filterd.txt -o liveSubDom/httpx/live.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with htppx" >> logs/logs_file.txt
        $liveCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : end of httpx" >> log/logs_file.txt
}
# Call
callLiveSub() {
    liveCheck=true
    liveSub
    if [ $liveCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : live subdomains failed" >> logs/logs_file.txt
        liveSub
        if [ $liveCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : live subdomains failed" >> logs/logs_file.txt
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callLiveSub
#####################################
# Port Scanning
portScan() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the start of masscan" >> log/logs_file.txt
    masscan -p0-79,81-442,444-65535 -iL Subdomain/ip_add.txt --rate=10000 -oB port_Scan/masscan/temp
    masscan --readscan port_Scan/masscan/temp | awk '{print $NF":"$4}' | cut -d/ -f1 >port_Scan/masscan/open_ports
    if [ $? -ne 0 ]; then
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with masscan" >> logs/logs_file.txt
        $portCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of masscan" >> log/logs_file.txt
    
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of nmap" >> log/logs_file.txt
    nmap  -sV -iL Subdomain/ip_add.txt -oN port_Scan/nmap/res_nmap.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with nmap" >> logs/logs_file.txt
        $portCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of nmap with succes" >> log/logs_file.txt
}
# Call
callPortScan() {
    portCheck=true
    portScan
    if [ $portCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : Port Scanning failed" >> logs/logs_file.txt
        portScan
        if [ $portCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : Port Scanning failed" >> logs/logs_file.txt
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callPortScan
#####################################
# Content Discovery
contentDis() {
    #echo "Starting with DirSearch"
    #dirsearch -u https://$domain -e php,asp,aspx,jsp,html,zip,jar,war,txt,log,conf,config,backup,old,sql,db,xml,svg,js,css -w wordlists/dirb/common.txt -o lastPart/contentDir/DirSearch/res_Dir.txt
    #while read subdomain; do
    #dirsearch -u https://$subdomain -e .php,.asp,.aspx,.jsp,.html,.zip,.jar,.war,.txt,.log,.conf,.config,.backup,.old,.sql,.db,.xml,.svg,.js,.css -w wordlists/dirb/common.txt -o lastPart/contentDir/DirSearch/res_Dir_$subdomain.txt
    #done < Subdomain/subdomains_filterd.txt
    #if [ $? -ne 0 ]; then
    #echo "Error: DirSearch failed"
    #$contentCheck=false
    #fi
    #echo "end of DirSearch"
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of ffuf" >> log/logs_file.txt
    ffuf -w wordlists/dirb/common.txt -u https://$domain/FUZZ -e .php,.asp,.aspx,.jsp,.html,.zip,.jar,.war,.txt,.log,.conf,.config,.backup,.old,.sql,.db,.xml,.svg,.js,.css -o lastPart/contentDir/fuzz/res_f.txt >/dev/null 2>&1
    while read subdomain; do
        ffuf -w wordlists/dirb/common.txt -u https://$subdomain/FUZZ -e .php,.asp,.aspx,.jsp,.html,.zip,.jar,.war,.txt,.log,.conf,.config,.backup,.old,.sql,.db,.xml,.svg,.js,.css -o lastPart/contentDir/fuzz/res_f_$subdomain.txt >/dev/null 2>&1
    done <Subdomain/subdomains_filterd.txt
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with ffuf" >> logs/logs_file.txt
        $contentCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of ffuf with succes" >> log/logs_file.txt
    cat lastPart/contentDir/DirSearch/res_Dir.txt lastPart/contentDir/fuzz/res_f.txt >lastPart/contentDir/res_final.txt
}
# Call
callContentDis() {
    contentCheck=true
    contentDis
    if [ $contentCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : Content Discovery failed" >> logs/logs_file.txt
        contentDis
        if [ $contentCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : Content Discovery failed" >> logs/logs_file.txt
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callContentDis
#####################################
# sub-subdomains enumeration
subSubEnum() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of altdns" >> log/logs_file.txt
    altdns -i Subdomain/subdomains_filterd.txt -o lastPart/subSub/res.txt -w wordlists/subSub.txt -r -s lastPart/subSub/resolved.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with altdns" >> logs/logs_file.txt
        $subSubCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of altdns with succes" >> log/logs_file.txt
}
# Call
callSubSubEnum() {
    subSubCheck=true
    subSubEnum
    if [ $subSubCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : sub-subdomains enumeration failed" >> logs/logs_file.txt
        subSubEnum
        if [ $subSubCheck == false ]; then
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : sub-subdomains enumeration failed" >> logs/logs_file.txt
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callSubSubEnum
#####################################
# waybackurls
wayback() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of wyback" >> log/logs_file.txt
    cat Subdomain/subdomains_filterd.txt | waybackurls >lastPart/backurl/wayback/res_way.txt
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with nmap" >> logs/logs_file.txt
        $waybackCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of wyback with succes" >> log/logs_file.txt
    cat lastPart/backurl/wayback/res_way.txt lastPart/contentDir/res_final.txt >lastPart/res_final.txt
}
# Call
callWayback() {
    waybackCheck=true
    wayback
    if [ $waybackCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : waybackurls failed" >> logs/logs_file.txt
        wayback
        if [ $waybackCheck == false ]; then
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : waybackurls failed" >> logs/logs_file.txt
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callWayback
#####################################
# gau
gau() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of gau" >> log/logs_file.txt
    cat Subdomain/subdomains_filterd.txt | gau -o lastPart/backurl/gau/res_gau.txt >/dev/null 2>&1
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with gau" >> logs/logs_file.txt
        $gauCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of gau with succes" >> log/logs_file.txt
}
# Call
callGau() {
    gauCheck=true
    gau
    if [ $gauCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : gau failed" >> logs/logs_file.txt
        gau
        if [ $gauCheck == false ]; then
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : gau failed" >> logs/logs_file.txt
             echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callGau
#####################################
# gf
gf() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of gf" >> log/logs_file.txt
    cat lastPart/res_final.txt | gf xss | tee -a lastPart/xssgf.txt
    cat lastPart/res_final.txt | gf ssti | tee -a lastPart/sstigf.txt
    cat lastPart/res_final.txt | gf sqli | tee -a lastPart/sqligf.txt
    cat lastPart/res_final.txt | gf ssrf | tee -a lastPart/ssrfgf.txt
    cat lastPart/res_final.txt | gf redirect | tee -a lastPart/redirectgf.txt
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with gf" >> logs/logs_file.txt
        $gfCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of gf with succes" >> log/logs_file.txt
}

# Call
callGf() {
    gfCheck=true
    gf
    if [ $gfCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : gf failed" >> logs/logs_file.txt
        gf
        if [ $gfCheck == false ]; then
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : gf failed" >> logs/logs_file.txt
            echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

        fi
    fi
}
callGf
#####################################
# scrapy
scrapy_func() {
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : start of Exctracting urls & js paths" >> log/logs_file.txt
    (cd lastPart/urlsJsScraper && scrapy crawl url_extractor -a subdomains_file=../../Subdomain/subdomains_filterd.txt -o ../UrlsJsPaths/results.json >/dev/null 2>&1)
    if [ $? -ne 0 ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : We have some problems with Exctracting urls & js paths" >> logs/logs_file.txt
        $scrapyCheck=false
    fi
    echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : the end of Exctracting urls & js paths with succes" >> log/logs_file.txt
}
# call
callScrapyFunc() {
    scrapyCheck=true
    scrapy_func
    if [ $scrapyCheck == false ]; then
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : ERROR : scrapy failed" >> logs/logs_file.txt
        echo "$(date '+%Y-%m-%d-%H-%M-%S') : $(whoami) : INFOS : Continuing with the rest of the script" >> log/logs_file.txt

    fi
}
